""" Example workflow for creating a JSON file for https://dms-viz.github.io/ """

# Import modules
import json
import pandas as pd
from os.path import join 

# Read in data
experiments = pd.read_csv("experiments.csv")

# Target rule
rule all:
    input:
        "data/output/example.json"


# Create JSON files for each experiment
rule create_viz_json:
    input:
        escape_df = "data/escape/{experiment}_avg.csv",
        sitemap_df = "data/site_numbering_map.csv",
        functional_score_df = "data/muteffects_observed.csv",
    output:
        "data/output/{experiment}.json"
    params: 
        name = lambda wildcards: wildcards.experiment,
        structure = lambda wildcards: experiments.loc[experiments['selection'] == wildcards.experiment, 'pdb'].item(),
        include_chains = lambda wildcards: experiments.loc[experiments['selection'] == wildcards.experiment, 'dataChains'].item(),
        exclude_chains = lambda wildcards: experiments.loc[experiments['selection'] == wildcards.experiment, 'excludedChains'].item(),
        filter_cols = (",").join(['times_seen', 'func_effect']),
        metric = "escape_mean"
    shell:
        """
        python create-viz-json.py \
            --input {input.escape_df} \
            --name {params.name} \
            --sitemap {input.sitemap_df} \
            --metric {params.metric} \
            --output {output} \
            --funcScores {input.functional_score_df} \
            --structure {params.structure} \
            --includedChains "{params.include_chains}" \
            --excludedChains "{params.exclude_chains}" \
            --filterCols {params.filter_cols} \
        """


# Combine JSON files into one
rule combine_jsons:
    input:
        input_files = expand("data/output/{experiment}.json", experiment=experiments.selection.unique())
    output:
        output_file = "data/output/example.json"
    run:
        combined_data = {}
        for input_file in input.input_files:
            with open(input_file) as f:
                data = json.load(f)
                combined_data.update(data)
        with open(output.output_file, 'w') as f:
            json.dump(combined_data, f)


